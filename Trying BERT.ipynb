{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e7fd47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras \n",
    "import tensorflow_hub as hub # to get our bert model\n",
    "import tensorflow_text as text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64805fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\" # for preprocessing\n",
    "encoder_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\" # for bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "489b4fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_preprocess_model = hub.KerasLayer(preprocess_url) # build preprocessing layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb9093a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_mask', 'input_type_ids', 'input_word_ids'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_test = ['nice movie indeed','I love python programming']\n",
    "text_preprocessed = bert_preprocess_model(text_test) # we preprocess the text using the preprocessing layer (produces a dictionary)\n",
    "text_preprocessed.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "180d3f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 128), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_preprocessed['input_mask']\n",
    "# we add [cls] token as the start of each sentence \n",
    "# and [sep] token at the end, so the first sentence consists of 5 words and the second consists of 6 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b1733c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 128), dtype=int32, numpy=\n",
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_preprocessed['input_type_ids'] \n",
    "# shape is (2,128) which means we have 2 sentences each of 128 words length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d99950e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 128), dtype=int32, numpy=\n",
       "array([[  101,  3835,  3185,  5262,   102,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0],\n",
       "       [  101,  1045,  2293, 18750,  4730,   102,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0]])>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_preprocessed['input_word_ids']\n",
    "# explains the id of each word in each sentence, 101--> CLS, 102--> SEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc5ca4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, we will build the bert model layer\n",
    "bert_model = hub.KerasLayer(encoder_url) # will take some time ~ 5 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58059fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['default', 'encoder_outputs', 'pooled_output', 'sequence_output'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_results = bert_model(text_preprocessed) # apply the model on the text_preprocessed dictionary created (produces a dictionary)\n",
    "bert_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7dd977d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 768), dtype=float32, numpy=\n",
       "array([[-0.791774  , -0.21411917,  0.49769533, ...,  0.24465217,\n",
       "        -0.47334474,  0.8175868 ],\n",
       "       [-0.9171231 , -0.47935176, -0.7865696 , ..., -0.61751723,\n",
       "        -0.7102685 ,  0.92184293]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_results['pooled_output']\n",
    "# the pooled output is the embeddings for the entire sentence so we have 2 vectors for our 2 sentences each of length 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f13abb6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 128, 768), dtype=float32, numpy=\n",
       "array([[[ 0.07292064,  0.08567819,  0.14476836, ..., -0.09677088,\n",
       "          0.08722144,  0.07711092],\n",
       "        [ 0.17839417, -0.19006042,  0.50349486, ..., -0.05869795,\n",
       "          0.32717082, -0.15578541],\n",
       "        [ 0.18701479, -0.43388715, -0.48875144, ..., -0.15502736,\n",
       "          0.00145109, -0.2447098 ],\n",
       "        ...,\n",
       "        [ 0.12083037,  0.12884255,  0.4645356 , ...,  0.07375544,\n",
       "          0.17441946,  0.16522126],\n",
       "        [ 0.07967836, -0.01190655,  0.5022546 , ...,  0.13777718,\n",
       "          0.21002199,  0.00624621],\n",
       "        [-0.072127  , -0.28303406,  0.5903339 , ...,  0.47551882,\n",
       "          0.16668493, -0.08920337]],\n",
       "\n",
       "       [[-0.07900581,  0.36335114, -0.21101557, ..., -0.17183751,\n",
       "          0.16299753,  0.67242676],\n",
       "        [ 0.2788351 ,  0.43716332, -0.3576475 , ..., -0.04463701,\n",
       "          0.3831518 ,  0.58879906],\n",
       "        [ 1.2037671 ,  1.0727016 ,  0.48408777, ...,  0.24920999,\n",
       "          0.4073099 ,  0.40481806],\n",
       "        ...,\n",
       "        [ 0.08630022,  0.19353811,  0.47540015, ...,  0.18880165,\n",
       "         -0.06474108,  0.31318617],\n",
       "        [ 0.15887032,  0.2857264 ,  0.37340805, ...,  0.09309098,\n",
       "         -0.04969548,  0.3876112 ],\n",
       "        [-0.08079877, -0.09572847,  0.26809788, ...,  0.1397965 ,\n",
       "         -0.06315817,  0.27288353]]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_results['sequence_output'] \n",
    "# the sequence output is the individual word embeddings so the shape is (2, 128, 768) which means we have 2 sentences each \n",
    "# one has 128 words and each word has an embedding of length 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da51e9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(2, 128, 768), dtype=float32, numpy=\n",
       " array([[[ 0.12901425,  0.00644747, -0.0361497 , ...,  0.04999633,\n",
       "           0.06149192, -0.02657545],\n",
       "         [ 1.1753384 ,  1.2140784 ,  1.1569979 , ...,  0.11634396,\n",
       "          -0.35855335, -0.40490183],\n",
       "         [ 0.03859033,  0.5386997 , -0.21089774, ...,  0.21858189,\n",
       "           0.72601664, -1.1158603 ],\n",
       "         ...,\n",
       "         [-0.07587016, -0.254219  ,  0.7075511 , ...,  0.50541997,\n",
       "          -0.1887868 ,  0.15028326],\n",
       "         [-0.16066611, -0.28089687,  0.57597065, ...,  0.52758545,\n",
       "          -0.11141388,  0.02887545],\n",
       "         [-0.04428154, -0.20279586,  0.5909355 , ...,  0.8133835 ,\n",
       "          -0.39075807, -0.02601737]],\n",
       " \n",
       "        [[ 0.18903585,  0.02752546, -0.06513744, ..., -0.00620212,\n",
       "           0.15053892,  0.03165444],\n",
       "         [ 0.5916151 ,  0.7589137 , -0.07240665, ...,  0.6190394 ,\n",
       "           0.8292891 ,  0.16161951],\n",
       "         [ 1.4460827 ,  0.44602644,  0.4099025 , ...,  0.48255914,\n",
       "           0.62691146,  0.13463417],\n",
       "         ...,\n",
       "         [ 0.15147904, -0.21573856,  0.70329064, ..., -0.12537214,\n",
       "          -0.13787258,  0.2772205 ],\n",
       "         [ 0.05143794, -0.24052712,  0.53569126, ..., -0.07915062,\n",
       "          -0.03307909,  0.17380911],\n",
       "         [ 0.20934707, -0.15645266,  0.60395443, ...,  0.3290352 ,\n",
       "          -0.35827187,  0.08100392]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 128, 768), dtype=float32, numpy=\n",
       " array([[[ 0.01418137, -0.22088261, -0.1502817 , ...,  0.11415625,\n",
       "           0.126181  ,  0.04843388],\n",
       "         [ 1.2033901 ,  1.346986  ,  1.7064525 , ...,  0.30610576,\n",
       "          -0.50742537, -0.55147463],\n",
       "         [ 0.42169082,  0.8110243 , -0.25631574, ..., -0.077225  ,\n",
       "           0.8937237 , -1.4472059 ],\n",
       "         ...,\n",
       "         [-0.19047475, -0.23860845,  0.8141206 , ...,  0.97493607,\n",
       "          -0.34774235, -0.08733568],\n",
       "         [-0.27151003, -0.31984976,  0.76593906, ...,  0.96761674,\n",
       "          -0.2951195 , -0.15731794],\n",
       "         [-0.2130274 , -0.19229692,  0.7338777 , ...,  1.1040442 ,\n",
       "          -0.451029  , -0.20683083]],\n",
       " \n",
       "        [[ 0.08973332, -0.18419707, -0.166451  , ...,  0.02761328,\n",
       "           0.11187714,  0.08041706],\n",
       "         [ 0.5831136 ,  0.5957025 ,  0.36019552, ...,  0.4127009 ,\n",
       "           0.26809162,  0.28400537],\n",
       "         [ 2.1166677 ,  0.517694  ,  0.86377496, ...,  0.71787333,\n",
       "           0.32405058,  0.09739982],\n",
       "         ...,\n",
       "         [ 0.24372889, -0.05775559,  0.6842874 , ...,  0.434836  ,\n",
       "          -0.57660943, -0.11131064],\n",
       "         [ 0.16803879, -0.03091825,  0.58638406, ...,  0.49625823,\n",
       "          -0.5056795 , -0.20782195],\n",
       "         [ 0.24831752,  0.00315502,  0.5159252 , ...,  0.8050239 ,\n",
       "          -0.6989965 , -0.24186423]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 128, 768), dtype=float32, numpy=\n",
       " array([[[ 0.022754  , -0.2798025 ,  0.02345701, ...,  0.27867043,\n",
       "           0.11714798,  0.18175074],\n",
       "         [ 1.2574842 ,  0.8725077 ,  1.6266011 , ...,  0.45210922,\n",
       "          -0.8090256 , -0.5448982 ],\n",
       "         [ 0.75219834,  0.63573647, -0.20566145, ..., -0.32381845,\n",
       "           0.7574951 , -1.458792  ],\n",
       "         ...,\n",
       "         [-0.15107416, -0.21129039,  0.96894634, ...,  1.1261967 ,\n",
       "          -0.0321409 , -0.2234026 ],\n",
       "         [-0.2812563 , -0.31140023,  0.8432894 , ...,  1.1342673 ,\n",
       "          -0.08336635, -0.25161234],\n",
       "         [-0.24449055, -0.21537857,  0.94809866, ...,  1.2419426 ,\n",
       "          -0.19873497, -0.33752578]],\n",
       " \n",
       "        [[ 0.10617059, -0.27990758, -0.01731798, ...,  0.20060444,\n",
       "           0.08148396,  0.21859051],\n",
       "         [ 0.6892587 ,  0.31591502,  0.55586624, ...,  0.6903949 ,\n",
       "          -0.07141601,  0.4140715 ],\n",
       "         [ 2.5758884 ,  0.6252086 ,  1.2503716 , ...,  0.4395771 ,\n",
       "          -0.18525624, -0.05004863],\n",
       "         ...,\n",
       "         [ 0.20464338, -0.01561969,  0.83431447, ...,  0.8014962 ,\n",
       "          -0.12853876, -0.35842046],\n",
       "         [-0.02875639,  0.05097821,  0.6815926 , ...,  0.9003149 ,\n",
       "          -0.12434878, -0.4225637 ],\n",
       "         [ 0.13327672,  0.02257314,  0.7722173 , ...,  1.0211186 ,\n",
       "          -0.30834717, -0.45623156]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 128, 768), dtype=float32, numpy=\n",
       " array([[[ 0.11484917, -0.64441085, -0.14245114, ...,  0.25474167,\n",
       "           0.00378418,  0.611051  ],\n",
       "         [ 1.3035426 ,  0.7706046 ,  1.3184991 , ...,  0.35822517,\n",
       "          -0.64121556, -0.32795393],\n",
       "         [ 1.1896739 ,  0.6279444 , -0.67501634, ..., -0.2887069 ,\n",
       "           0.477919  , -1.2806002 ],\n",
       "         ...,\n",
       "         [-0.22614759, -0.6276291 ,  1.0227485 , ...,  0.8292314 ,\n",
       "          -0.40314716,  0.04389274],\n",
       "         [-0.3990149 , -0.75619024,  0.74893856, ...,  0.74922615,\n",
       "          -0.45077735, -0.0036796 ],\n",
       "         [-0.37728772, -0.783104  ,  0.9057252 , ...,  0.97362286,\n",
       "          -0.48285758, -0.07389833]],\n",
       " \n",
       "        [[ 0.15151364, -0.7075227 , -0.27520436, ...,  0.4434589 ,\n",
       "          -0.209204  ,  0.49860147],\n",
       "         [ 0.8864793 , -0.2483818 ,  0.7353747 , ...,  0.7417941 ,\n",
       "          -0.13177228,  0.10158461],\n",
       "         [ 2.5865812 ,  0.6188284 ,  0.5279888 , ...,  0.84873044,\n",
       "          -0.5915019 ,  0.02349854],\n",
       "         ...,\n",
       "         [-0.05526865, -0.43394673,  1.1783335 , ...,  0.9179172 ,\n",
       "          -0.45718125, -0.25014627],\n",
       "         [-0.2932866 , -0.23091242,  0.9938014 , ...,  1.0353789 ,\n",
       "          -0.4243576 , -0.34947643],\n",
       "         [-0.15899119, -0.5009815 ,  0.98142105, ...,  1.1373074 ,\n",
       "          -0.61888385, -0.44457772]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 128, 768), dtype=float32, numpy=\n",
       " array([[[-0.22174793, -0.4222532 , -0.04923997, ..., -0.26284236,\n",
       "           0.06099954,  0.63794875],\n",
       "         [ 1.1627907 ,  0.6770535 ,  1.3072388 , ...,  0.2279471 ,\n",
       "          -0.54329526, -0.27383307],\n",
       "         [ 1.530824  ,  0.722255  , -0.43608665, ...,  0.2743577 ,\n",
       "           0.24980251, -0.9875377 ],\n",
       "         ...,\n",
       "         [-0.17669764, -0.3126049 ,  1.0875319 , ...,  0.5924214 ,\n",
       "           0.01275329, -0.28171915],\n",
       "         [-0.34473774, -0.4242998 ,  0.87980264, ...,  0.5482606 ,\n",
       "          -0.08151931, -0.3400143 ],\n",
       "         [-0.48139876, -0.31324217,  1.1702352 , ...,  0.87309843,\n",
       "          -0.07970165, -0.45325506]],\n",
       " \n",
       "        [[-0.21608154, -0.8986419 , -0.4499155 , ..., -0.0828624 ,\n",
       "          -0.17226866,  0.66199857],\n",
       "         [ 0.666145  , -0.5491696 ,  0.46460587, ...,  0.17649367,\n",
       "           0.22822493,  0.34962136],\n",
       "         [ 2.0629625 ,  0.6991982 ,  0.3560455 , ...,  0.529533  ,\n",
       "          -0.34809303,  0.0083136 ],\n",
       "         ...,\n",
       "         [-0.11594   , -0.17149279,  0.89943993, ...,  0.6299014 ,\n",
       "          -0.33990213, -0.20049235],\n",
       "         [-0.13007542, -0.02739059,  0.7079981 , ...,  0.8059456 ,\n",
       "          -0.30724132, -0.19956355],\n",
       "         [-0.2631487 , -0.26137066,  0.63385665, ...,  0.81501764,\n",
       "          -0.454003  , -0.3512061 ]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 128, 768), dtype=float32, numpy=\n",
       " array([[[-0.03392643, -0.39431486,  0.04223733, ..., -0.07905583,\n",
       "           0.01993854,  0.7692064 ],\n",
       "         [ 1.4294361 , -0.08699042,  1.5299487 , ...,  0.22512178,\n",
       "          -1.0060079 , -0.23702295],\n",
       "         [ 1.5031747 ,  0.6725799 , -0.5259019 , ...,  0.10906857,\n",
       "           0.2704241 , -1.25675   ],\n",
       "         ...,\n",
       "         [-0.30033565, -0.02261845,  1.318741  , ...,  0.69288754,\n",
       "          -0.09798452, -0.17419675],\n",
       "         [-0.43754143, -0.21149167,  1.1094577 , ...,  0.5006598 ,\n",
       "          -0.17692396, -0.1852912 ],\n",
       "         [-0.6592049 , -0.19607843,  1.3134075 , ...,  0.7320078 ,\n",
       "          -0.19967367, -0.3246913 ]],\n",
       " \n",
       "        [[-0.27334654, -0.9526847 , -0.78696615, ..., -0.12205365,\n",
       "          -0.08783773,  0.7581165 ],\n",
       "         [ 0.46757   , -0.16237532, -0.01155873, ...,  0.18781263,\n",
       "           0.621647  ,  0.03009851],\n",
       "         [ 1.79474   ,  0.905108  ,  0.08580964, ...,  0.77093506,\n",
       "          -0.66827863, -0.06755506],\n",
       "         ...,\n",
       "         [-0.18337417, -0.15806611,  1.1826946 , ...,  0.8304753 ,\n",
       "          -0.3940642 , -0.23047736],\n",
       "         [-0.22270186,  0.00976016,  0.9340851 , ...,  1.1286675 ,\n",
       "          -0.3488432 , -0.19491448],\n",
       "         [-0.30386114, -0.2968309 ,  0.82471645, ...,  1.0090809 ,\n",
       "          -0.46407592, -0.3146555 ]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 128, 768), dtype=float32, numpy=\n",
       " array([[[-0.23803389, -0.6655407 ,  0.29917192, ...,  0.03415139,\n",
       "           0.29362798,  0.9653624 ],\n",
       "         [ 1.5040761 ,  0.0069505 ,  1.4314135 , ...,  0.24628775,\n",
       "          -0.5521964 , -0.32215548],\n",
       "         [ 1.3629028 ,  0.47741824, -0.61529905, ...,  0.08586918,\n",
       "           0.43922496, -1.5594153 ],\n",
       "         ...,\n",
       "         [-0.16864008,  0.00209763,  1.3201771 , ...,  0.94280374,\n",
       "          -0.04737356,  0.21490426],\n",
       "         [-0.26666382, -0.24881166,  1.2213266 , ...,  0.6352797 ,\n",
       "          -0.04442453,  0.04466262],\n",
       "         [-0.5336612 , -0.35795987,  1.3447877 , ...,  0.6038446 ,\n",
       "          -0.08427184, -0.15711978]],\n",
       " \n",
       "        [[-0.05967452, -0.8448216 , -0.8939021 , ..., -0.10864021,\n",
       "           0.4093243 ,  0.7940859 ],\n",
       "         [ 0.5440508 , -0.3196298 , -0.45491517, ...,  0.48068637,\n",
       "           0.77862537,  0.22774252],\n",
       "         [ 1.4479868 ,  1.1230618 ,  0.09568028, ...,  1.3554287 ,\n",
       "           0.06143587, -0.00836904],\n",
       "         ...,\n",
       "         [ 0.25652316, -0.14106587,  1.185434  , ...,  0.956837  ,\n",
       "          -0.21603908, -0.06946392],\n",
       "         [ 0.2581911 ,  0.07949236,  0.98516536, ...,  1.0518216 ,\n",
       "          -0.07890883, -0.1284152 ],\n",
       "         [-0.05268861, -0.33431315,  0.96373385, ...,  0.8960693 ,\n",
       "          -0.10082343, -0.2812957 ]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 128, 768), dtype=float32, numpy=\n",
       " array([[[-7.08267391e-02, -2.56899565e-01, -3.59624028e-02, ...,\n",
       "          -3.58812869e-01,  1.35247841e-01,  1.01361060e+00],\n",
       "         [ 9.74719286e-01, -1.97128952e-01,  1.43180764e+00, ...,\n",
       "          -1.40520513e-01, -5.04320636e-02, -2.71423925e-02],\n",
       "         [ 1.12733996e+00,  2.71228105e-01, -2.86229163e-01, ...,\n",
       "           9.33854580e-02,  2.99082369e-01, -1.37644434e+00],\n",
       "         ...,\n",
       "         [-9.57870111e-02,  2.91808546e-01,  1.58791566e+00, ...,\n",
       "           8.50042164e-01, -5.12850583e-02,  2.03401029e-01],\n",
       "         [-2.22688735e-01, -8.38951245e-02,  1.72560132e+00, ...,\n",
       "           6.12222016e-01,  1.09765716e-01,  7.00466856e-02],\n",
       "         [-5.78300416e-01, -3.59155864e-01,  1.60359693e+00, ...,\n",
       "           3.41898620e-01,  5.28811514e-02, -1.54008836e-01]],\n",
       " \n",
       "        [[ 6.10172972e-02, -3.51616412e-01, -8.48914444e-01, ...,\n",
       "          -4.85550314e-01,  4.27030981e-01,  6.38289928e-01],\n",
       "         [ 6.63765311e-01,  1.82037242e-04, -7.90788352e-01, ...,\n",
       "           3.06870043e-01,  7.58436978e-01,  7.32401192e-01],\n",
       "         [ 1.44947040e+00,  1.12650418e+00,  1.77092388e-01, ...,\n",
       "           2.34715432e-01,  3.49295259e-01,  4.37097758e-01],\n",
       "         ...,\n",
       "         [ 3.23395818e-01,  1.75758034e-01,  8.76723111e-01, ...,\n",
       "           9.89041090e-01, -2.70507604e-01, -3.08094114e-01],\n",
       "         [ 4.04043019e-01,  5.13649404e-01,  7.27481484e-01, ...,\n",
       "           9.49420631e-01, -1.02151614e-02, -3.46443295e-01],\n",
       "         [-9.12981760e-03, -8.70161951e-02,  7.30317831e-01, ...,\n",
       "           8.54396701e-01, -1.36611879e-01, -4.74934906e-01]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 128, 768), dtype=float32, numpy=\n",
       " array([[[-0.0940345 , -0.05987631, -0.01171673, ..., -0.2216758 ,\n",
       "          -0.07650092,  0.57658106],\n",
       "         [ 0.77480686,  0.1518829 ,  1.0920002 , ..., -0.19562379,\n",
       "           0.15173186, -0.01071488],\n",
       "         [ 0.8519134 ,  0.2584276 , -0.7703555 , ...,  0.03356656,\n",
       "           0.3401045 , -1.3918685 ],\n",
       "         ...,\n",
       "         [-0.19780381,  0.52819747,  0.90235364, ...,  0.27919757,\n",
       "          -0.28764138,  0.7510938 ],\n",
       "         [-0.3506746 ,  0.09291998,  1.3383341 , ...,  0.2261961 ,\n",
       "          -0.03589065,  0.27343988],\n",
       "         [-0.90445095, -0.20991138,  1.1977341 , ...,  0.35118526,\n",
       "          -0.21743691,  0.01482401]],\n",
       " \n",
       "        [[-0.07011142, -0.02392511, -0.61924326, ..., -0.14542103,\n",
       "           0.34049377,  0.4122472 ],\n",
       "         [ 0.5926159 ,  0.19015901, -0.37399524, ...,  0.37239593,\n",
       "           0.39152896,  0.42580402],\n",
       "         [ 1.1394776 ,  0.8439858 ,  0.38894024, ...,  0.2089829 ,\n",
       "           0.25176373,  0.26400024],\n",
       "         ...,\n",
       "         [ 0.4330598 ,  0.42012164,  1.0965099 , ...,  1.1872362 ,\n",
       "          -0.16672054,  0.00856209],\n",
       "         [ 0.57542396,  0.86609405,  1.1184691 , ...,  1.0475055 ,\n",
       "           0.04264341, -0.01540388],\n",
       "         [-0.05487908, -0.07306871,  0.9012211 , ...,  0.80045223,\n",
       "          -0.168206  , -0.3550736 ]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 128, 768), dtype=float32, numpy=\n",
       " array([[[-0.22671345,  0.03110836,  0.32186088, ..., -0.28090224,\n",
       "          -0.7505078 ,  0.44557953],\n",
       "         [ 0.7712561 ,  0.11217982,  0.66033155, ..., -0.09223752,\n",
       "           0.34821144, -0.36905184],\n",
       "         [ 0.51224047, -0.19928929, -0.8477504 , ..., -0.2881206 ,\n",
       "           0.22383736, -1.2124602 ],\n",
       "         ...,\n",
       "         [ 0.12500648,  0.66633946,  0.9852215 , ..., -0.08709399,\n",
       "          -0.58054703,  0.61272395],\n",
       "         [ 0.01400259,  0.1047124 ,  1.2684819 , ..., -0.01833207,\n",
       "          -0.35933286,  0.15463261],\n",
       "         [-0.80938417, -0.36067975,  1.350127  , ...,  0.58935964,\n",
       "          -0.5093237 , -0.09766845]],\n",
       " \n",
       "        [[-0.21535029, -0.2396224 , -0.30932385, ..., -0.25965002,\n",
       "           0.09695277,  0.41826668],\n",
       "         [ 0.5070058 , -0.01544859, -0.10519613, ...,  0.38675314,\n",
       "           0.22041114, -0.10293267],\n",
       "         [ 1.0366052 ,  0.9171308 ,  0.26164252, ...,  0.3318217 ,\n",
       "           0.45597076,  0.12697908],\n",
       "         ...,\n",
       "         [ 0.16190556,  0.76270086,  1.273767  , ...,  0.5725998 ,\n",
       "          -0.05929481,  0.26224115],\n",
       "         [ 0.46124542,  1.1673871 ,  0.95947737, ...,  0.46032992,\n",
       "           0.13521384,  0.45136008],\n",
       "         [-0.24183993,  0.17352743,  0.8415644 , ...,  0.24766843,\n",
       "          -0.14810178,  0.06557371]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 128, 768), dtype=float32, numpy=\n",
       " array([[[-2.19515711e-02,  2.13036150e-01,  3.11359406e-01, ...,\n",
       "          -2.39179432e-01, -2.78708309e-01,  2.04084828e-01],\n",
       "         [ 8.30984473e-01,  1.90781653e-01,  7.11346030e-01, ...,\n",
       "          -3.00243765e-01,  3.11524242e-01, -2.59341002e-01],\n",
       "         [ 3.73089433e-01, -4.22125727e-01, -6.66909099e-01, ...,\n",
       "          -4.52975929e-01,  3.20451796e-01, -2.99886227e-01],\n",
       "         ...,\n",
       "         [ 3.31664950e-01,  7.18358457e-01,  8.99611413e-01, ...,\n",
       "          -3.49144787e-01, -2.99870402e-01,  5.23888707e-01],\n",
       "         [ 2.38531992e-01,  2.04843953e-01,  1.13064313e+00, ...,\n",
       "          -1.51131019e-01, -1.37812123e-01,  7.69999847e-02],\n",
       "         [-3.84120882e-01, -3.81585956e-01,  1.33972836e+00, ...,\n",
       "           5.77554405e-01, -1.55400276e-01, -2.92944878e-01]],\n",
       " \n",
       "        [[ 1.43630356e-01,  1.69801682e-01,  4.51204889e-02, ...,\n",
       "          -6.21681921e-02, -1.57531835e-02,  2.87869841e-01],\n",
       "         [ 5.84759891e-01,  2.69932896e-01, -2.85206497e-01, ...,\n",
       "           3.38930637e-01,  1.17772914e-01,  3.69868316e-02],\n",
       "         [ 1.25257862e+00,  1.25564396e+00,  3.87544751e-01, ...,\n",
       "           1.72757223e-01,  4.96662736e-01,  6.13781035e-01],\n",
       "         ...,\n",
       "         [ 1.95485979e-01,  4.40819174e-01,  1.03893614e+00, ...,\n",
       "           1.45270422e-01, -2.77438998e-01,  1.90322518e-01],\n",
       "         [ 4.48164940e-01,  7.64476955e-01,  6.98005080e-01, ...,\n",
       "          -8.36132094e-04, -7.96439797e-02,  4.93358493e-01],\n",
       "         [-2.33980626e-01, -2.03335762e-01,  3.48247647e-01, ...,\n",
       "          -6.43418059e-02, -3.20875406e-01,  2.23342292e-02]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 128, 768), dtype=float32, numpy=\n",
       " array([[[ 0.07292064,  0.08567819,  0.14476836, ..., -0.09677088,\n",
       "           0.08722144,  0.07711092],\n",
       "         [ 0.17839417, -0.19006042,  0.50349486, ..., -0.05869795,\n",
       "           0.32717082, -0.15578541],\n",
       "         [ 0.18701479, -0.43388715, -0.48875144, ..., -0.15502736,\n",
       "           0.00145109, -0.2447098 ],\n",
       "         ...,\n",
       "         [ 0.12083037,  0.12884255,  0.4645356 , ...,  0.07375544,\n",
       "           0.17441946,  0.16522126],\n",
       "         [ 0.07967836, -0.01190655,  0.5022546 , ...,  0.13777718,\n",
       "           0.21002199,  0.00624621],\n",
       "         [-0.072127  , -0.28303406,  0.5903339 , ...,  0.47551882,\n",
       "           0.16668493, -0.08920337]],\n",
       " \n",
       "        [[-0.07900581,  0.36335114, -0.21101557, ..., -0.17183751,\n",
       "           0.16299753,  0.67242676],\n",
       "         [ 0.2788351 ,  0.43716332, -0.3576475 , ..., -0.04463701,\n",
       "           0.3831518 ,  0.58879906],\n",
       "         [ 1.2037671 ,  1.0727016 ,  0.48408777, ...,  0.24920999,\n",
       "           0.4073099 ,  0.40481806],\n",
       "         ...,\n",
       "         [ 0.08630022,  0.19353811,  0.47540015, ...,  0.18880165,\n",
       "          -0.06474108,  0.31318617],\n",
       "         [ 0.15887032,  0.2857264 ,  0.37340805, ...,  0.09309098,\n",
       "          -0.04969548,  0.3876112 ],\n",
       "         [-0.08079877, -0.09572847,  0.26809788, ...,  0.1397965 ,\n",
       "          -0.06315817,  0.27288353]]], dtype=float32)>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(bert_results['encoder_outputs'])) # we use bert base which have 12 encoders. each layer has 768 size embedding vector\n",
    "bert_results['encoder_outputs'] \n",
    "# each layer has output of (2, 128, 768) embeddings for all words\n",
    "# the output of the last (final) encoder is the same as our sequence_output (final words embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8cf08f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 128, 768), dtype=bool, numpy=\n",
       "array([[[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]]])>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_results['encoder_outputs'][-1] == bert_results['sequence_output'] # proving the last encoder output is our final words embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed92ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
